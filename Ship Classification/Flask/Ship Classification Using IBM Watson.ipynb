{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe72e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed586580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b00783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = pd.read_csv(r'D:\\smartinternz\\Ship Classification\\input\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79162581",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(r'D:\\smartinternz\\Ship Classification\\input\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd7c9563",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels['category'] = train_labels['category'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23fd22de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2823080.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2870024.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2662125.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2900420.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2804883.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image  category\n",
       "0  2823080.jpg         0\n",
       "1  2870024.jpg         0\n",
       "2  2662125.jpg         1\n",
       "3  2900420.jpg         2\n",
       "4  2804883.jpg         1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74e0c1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2823080.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2870024.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2662125.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2900420.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2804883.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image  category\n",
       "0  2823080.jpg         1\n",
       "1  2870024.jpg         1\n",
       "2  2662125.jpg         2\n",
       "3  2900420.jpg         3\n",
       "4  2804883.jpg         2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba80620c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>category</th>\n",
       "      <th>ship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2823080.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2870024.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2662125.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>Military</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2900420.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>Carrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2804883.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>Military</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image  category      ship\n",
       "0  2823080.jpg         1     Cargo\n",
       "1  2870024.jpg         1     Cargo\n",
       "2  2662125.jpg         2  Military\n",
       "3  2900420.jpg         3   Carrier\n",
       "4  2804883.jpg         2  Military"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ship = {1 :'Cargo' , \n",
    "        2:'Military', \n",
    "        3:'Carrier', \n",
    "        4:'Cruise', \n",
    "        5:'Tankers'}\n",
    "\n",
    "train_files['ship'] = train_files['category'].map(ship).astype('category')\n",
    "\n",
    "train_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb120566",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'D:/smartinternz/Ship Classification/input/train\\\\Cargo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m class_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(labels\u001b[38;5;241m.\u001b[39mship\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m class_names:\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD:/smartinternz/Ship Classification/input/train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\New folder\\lib\\os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'D:/smartinternz/Ship Classification/input/train\\\\Cargo'"
     ]
    }
   ],
   "source": [
    "labels = train_files.sort_values('ship')\n",
    "class_names = list(labels.ship.unique())\n",
    "for i in class_names:\n",
    "    os.makedirs(os.path.join('D:/smartinternz/Ship Classification/input/train',i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f57d765",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/smartinternz/Ship Classification/input/images\\\\2823080.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\New folder\\lib\\shutil.py:823\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'D:/smartinternz/Ship Classification/input/images\\\\2823080.jpg' -> 'D:/smartinternz/Ship Classification/input/trainCargo'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(labels[labels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mship\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mc][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m      4\u001b[0m     get_image \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/smartinternz/Ship Classification/input/images\u001b[39m\u001b[38;5;124m'\u001b[39m,i)\n\u001b[1;32m----> 5\u001b[0m     move_image_to_cat \u001b[38;5;241m=\u001b[39m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:/smartinternz/Ship Classification/input/train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\New folder\\lib\\shutil.py:843\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    841\u001b[0m         rmtree(src)\n\u001b[0;32m    842\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 843\u001b[0m         \u001b[43mcopy_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    844\u001b[0m         os\u001b[38;5;241m.\u001b[39munlink(src)\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m real_dst\n",
      "File \u001b[1;32m~\\New folder\\lib\\shutil.py:444\u001b[0m, in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[0;32m    443\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[1;32m--> 444\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m copystat(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32m~\\New folder\\lib\\shutil.py:264\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    262\u001b[0m     os\u001b[38;5;241m.\u001b[39msymlink(os\u001b[38;5;241m.\u001b[39mreadlink(src), dst)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[0;32m    267\u001b[0m                 \u001b[38;5;66;03m# macOS\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/smartinternz/Ship Classification/input/images\\\\2823080.jpg'"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "for c in class_names : \n",
    "    for i in list(labels[labels['ship']==c]['image']):\n",
    "        get_image = os.path.join('D:/smartinternz/Ship Classification/input/images',i)\n",
    "        move_image_to_cat = shutil.move(get_image, \"D:/smartinternz/Ship Classification/input/train\"+c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8a1ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6390f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=45,\n",
    "                                  horizontal_flip=True,\n",
    "                                  width_shift_range=0.5,\n",
    "                                  height_shift_range=0.5,\n",
    "                                  validation_split=0.2,\n",
    "                                  preprocessing_function=preprocess_input\n",
    "                                  )\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d35f6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5003 images belonging to 5 classes.\n",
      "Found 1249 images belonging to 5 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "train_set = train_datagen.flow_from_directory('D:/smartinternz/Ship Classification/input/train/',\n",
    "                                              batch_size=16, subset='training',\n",
    "                                              target_size=(224,224))\n",
    "validation_set = train_datagen.flow_from_directory('D:/smartinternz/Ship Classification/input/train/',\n",
    "                                                   batch_size=16, subset='validation',\n",
    "                                                   target_size=(224,224))\n",
    "test_set = test_datagen.flow_from_directory('D:/smartinternz/Ship Classification/input/test/',batch_size=16,\n",
    "                                            target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b609283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Flatten, Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61cf21c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape,n_classes, optimizer='rmsprop'):\n",
    "    conv_base= VGG16(include_top = False,\n",
    "                     weights='imagenet',\n",
    "                     input_shape=input_shape)\n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False \n",
    "    top_model = conv_base.output\n",
    "    top_model = Flatten(name=\"flatten\")(top_model)\n",
    "    top_model = Dense(4096, activation='relu')(top_model)\n",
    "    top_model = Dense(1072, activation='relu')(top_model)\n",
    "    top_model = Dropout(0.2)(top_model)\n",
    "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
    "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
    "    model.compile (optimizer = optimizer,\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "870f45d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82033990",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224,224,3)\n",
    "optim = Adam(learning_rate=0.001)\n",
    "weights = 'imagenet'\n",
    "n_classes=5\n",
    "vgg_model = create_model(input_shape, n_classes, optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58062421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1072)              4391984   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1072)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 5365      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,876,581\n",
      "Trainable params: 107,161,893\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bb487ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "cp = ModelCheckpoint('best.hdf5', monitor = 'val_loss',verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f226aad2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KAREEM\\AppData\\Local\\Temp\\ipykernel_19596\\1604804611.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = vgg_model.fit_generator(generator=train_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 6.8804 - accuracy: 0.5266\n",
      "Epoch 1: val_loss improved from inf to 0.97463, saving model to best.hdf5\n",
      "312/312 [==============================] - 911s 3s/step - loss: 6.8804 - accuracy: 0.5266 - val_loss: 0.9746 - val_accuracy: 0.6354\n",
      "Epoch 2/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8876 - accuracy: 0.6671\n",
      "Epoch 2: val_loss improved from 0.97463 to 0.89312, saving model to best.hdf5\n",
      "312/312 [==============================] - 899s 3s/step - loss: 0.8876 - accuracy: 0.6671 - val_loss: 0.8931 - val_accuracy: 0.6562\n",
      "Epoch 3/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8434 - accuracy: 0.6854\n",
      "Epoch 3: val_loss did not improve from 0.89312\n",
      "312/312 [==============================] - 895s 3s/step - loss: 0.8434 - accuracy: 0.6854 - val_loss: 0.9696 - val_accuracy: 0.6859\n",
      "Epoch 4/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8062 - accuracy: 0.6916\n",
      "Epoch 4: val_loss improved from 0.89312 to 0.79175, saving model to best.hdf5\n",
      "312/312 [==============================] - 2930s 9s/step - loss: 0.8062 - accuracy: 0.6916 - val_loss: 0.7918 - val_accuracy: 0.7075\n",
      "Epoch 5/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7392 - accuracy: 0.7189\n",
      "Epoch 5: val_loss did not improve from 0.79175\n",
      "312/312 [==============================] - 1011s 3s/step - loss: 0.7392 - accuracy: 0.7189 - val_loss: 0.7939 - val_accuracy: 0.7043\n",
      "Epoch 6/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7208 - accuracy: 0.7363\n",
      "Epoch 6: val_loss improved from 0.79175 to 0.73176, saving model to best.hdf5\n",
      "312/312 [==============================] - 926s 3s/step - loss: 0.7208 - accuracy: 0.7363 - val_loss: 0.7318 - val_accuracy: 0.7260\n",
      "Epoch 7/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7204 - accuracy: 0.7363\n",
      "Epoch 7: val_loss did not improve from 0.73176\n",
      "312/312 [==============================] - 910s 3s/step - loss: 0.7204 - accuracy: 0.7363 - val_loss: 0.7353 - val_accuracy: 0.7428\n",
      "Epoch 8/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7105 - accuracy: 0.7357\n",
      "Epoch 8: val_loss improved from 0.73176 to 0.72476, saving model to best.hdf5\n",
      "312/312 [==============================] - 1834s 6s/step - loss: 0.7105 - accuracy: 0.7357 - val_loss: 0.7248 - val_accuracy: 0.7380\n",
      "Epoch 9/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7212 - accuracy: 0.7313\n",
      "Epoch 9: val_loss did not improve from 0.72476\n",
      "312/312 [==============================] - 2601s 8s/step - loss: 0.7212 - accuracy: 0.7313 - val_loss: 0.7689 - val_accuracy: 0.7276\n",
      "Epoch 10/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6776 - accuracy: 0.7467\n",
      "Epoch 10: val_loss did not improve from 0.72476\n",
      "312/312 [==============================] - 942s 3s/step - loss: 0.6776 - accuracy: 0.7467 - val_loss: 0.7466 - val_accuracy: 0.7548\n",
      "Epoch 11/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6801 - accuracy: 0.7491\n",
      "Epoch 11: val_loss did not improve from 0.72476\n",
      "312/312 [==============================] - 926s 3s/step - loss: 0.6801 - accuracy: 0.7491 - val_loss: 0.8020 - val_accuracy: 0.7284\n",
      "Epoch 12/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6666 - accuracy: 0.7656\n",
      "Epoch 12: val_loss improved from 0.72476 to 0.68801, saving model to best.hdf5\n",
      "312/312 [==============================] - 958s 3s/step - loss: 0.6666 - accuracy: 0.7656 - val_loss: 0.6880 - val_accuracy: 0.7412\n",
      "Epoch 13/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6602 - accuracy: 0.7574\n",
      "Epoch 13: val_loss did not improve from 0.68801\n",
      "312/312 [==============================] - 1124s 4s/step - loss: 0.6602 - accuracy: 0.7574 - val_loss: 0.7072 - val_accuracy: 0.7356\n",
      "Epoch 14/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6901 - accuracy: 0.7477\n",
      "Epoch 14: val_loss improved from 0.68801 to 0.67677, saving model to best.hdf5\n",
      "312/312 [==============================] - 1050s 3s/step - loss: 0.6901 - accuracy: 0.7477 - val_loss: 0.6768 - val_accuracy: 0.7580\n",
      "Epoch 15/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6777 - accuracy: 0.7473\n",
      "Epoch 15: val_loss did not improve from 0.67677\n",
      "312/312 [==============================] - 1143s 4s/step - loss: 0.6777 - accuracy: 0.7473 - val_loss: 0.6779 - val_accuracy: 0.7452\n",
      "Epoch 16/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6175 - accuracy: 0.7702\n",
      "Epoch 16: val_loss did not improve from 0.67677\n",
      "312/312 [==============================] - 1026s 3s/step - loss: 0.6175 - accuracy: 0.7702 - val_loss: 0.6870 - val_accuracy: 0.7564\n",
      "Epoch 17/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6453 - accuracy: 0.7672\n",
      "Epoch 17: val_loss did not improve from 0.67677\n",
      "312/312 [==============================] - 1037s 3s/step - loss: 0.6453 - accuracy: 0.7672 - val_loss: 0.7266 - val_accuracy: 0.7115\n",
      "Epoch 18/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6554 - accuracy: 0.7668\n",
      "Epoch 18: val_loss improved from 0.67677 to 0.66354, saving model to best.hdf5\n",
      "312/312 [==============================] - 976s 3s/step - loss: 0.6554 - accuracy: 0.7668 - val_loss: 0.6635 - val_accuracy: 0.7620\n",
      "Epoch 19/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6406 - accuracy: 0.7694\n",
      "Epoch 19: val_loss did not improve from 0.66354\n",
      "312/312 [==============================] - 1315s 4s/step - loss: 0.6406 - accuracy: 0.7694 - val_loss: 0.8376 - val_accuracy: 0.7492\n",
      "Epoch 20/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6652 - accuracy: 0.7686\n",
      "Epoch 20: val_loss did not improve from 0.66354\n",
      "312/312 [==============================] - 1282s 4s/step - loss: 0.6652 - accuracy: 0.7686 - val_loss: 0.7034 - val_accuracy: 0.7612\n",
      "Epoch 21/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6374 - accuracy: 0.7604\n",
      "Epoch 21: val_loss did not improve from 0.66354\n",
      "312/312 [==============================] - 932s 3s/step - loss: 0.6374 - accuracy: 0.7604 - val_loss: 0.7017 - val_accuracy: 0.7236\n",
      "Epoch 22/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6137 - accuracy: 0.7812\n",
      "Epoch 22: val_loss improved from 0.66354 to 0.65844, saving model to best.hdf5\n",
      "312/312 [==============================] - 926s 3s/step - loss: 0.6137 - accuracy: 0.7812 - val_loss: 0.6584 - val_accuracy: 0.7572\n",
      "Epoch 23/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6279 - accuracy: 0.7746\n",
      "Epoch 23: val_loss did not improve from 0.65844\n",
      "312/312 [==============================] - 890s 3s/step - loss: 0.6279 - accuracy: 0.7746 - val_loss: 0.6674 - val_accuracy: 0.7700\n",
      "Epoch 24/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6102 - accuracy: 0.7768\n",
      "Epoch 24: val_loss improved from 0.65844 to 0.65799, saving model to best.hdf5\n",
      "312/312 [==============================] - 895s 3s/step - loss: 0.6102 - accuracy: 0.7768 - val_loss: 0.6580 - val_accuracy: 0.7468\n",
      "Epoch 25/25\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6214 - accuracy: 0.7646\n",
      "Epoch 25: val_loss improved from 0.65799 to 0.63917, saving model to best.hdf5\n",
      "312/312 [==============================] - 892s 3s/step - loss: 0.6214 - accuracy: 0.7646 - val_loss: 0.6392 - val_accuracy: 0.7925\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "history = vgg_model.fit_generator(generator=train_set,\n",
    "                                 steps_per_epoch=train_set.n//train_set.batch_size,\n",
    "                                 validation_steps = validation_set.n//validation_set.batch_size,\n",
    "                                 validation_data=validation_set,\n",
    "                                 callbacks=[cp],\n",
    "                                 epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "828344f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.save('vgg16-ship-classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0cd16ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 493ms/step\n",
      "Cargo\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img= image.load_img('D:/smartinternz/Ship Classification/input/test/Cargo/Cargo1.jpg',target_size=(224,224))\n",
    "img = image.img_to_array(img)\n",
    "img = img.reshape((1,img.shape[0], img.shape[1], img.shape[2]))\n",
    "img = preprocess_input(img)\n",
    "\n",
    "pred = vgg_model.predict(img)\n",
    "pred = pred.flatten()\n",
    "pred= list(pred)\n",
    "m = max(pred)\n",
    "\n",
    "val_dict = {0:'Cargo', 1:'Carrier', 2:'Cruise', 3:'Military', 4:'Tankers'}\n",
    "result=val_dict[pred.index(m)]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0420dc97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f066ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d6d73d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a2c84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
